{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: PenDigits\n",
    "\n",
    "Source: http://www.timeseriesclassification.com/description.php?Dataset=PenDigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arff\n",
    "import timeit\n",
    "# utils \n",
    "from sklearn.model_selection import train_test_split\n",
    "# models\n",
    "from sklearn import svm\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Data sets\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples shape (7494, 17)\n",
      "Test sample shape (3498, 17)\n"
     ]
    }
   ],
   "source": [
    "path_train_dimension_1 = './datasets/PenDigits/PenDigitsDimension1_TRAIN.arff'\n",
    "path_train_dimension_2 = './datasets/PenDigits/PenDigitsDimension2_TRAIN.arff'\n",
    "path_test_dimension_1 = './datasets/PenDigits/PenDigitsDimension1_TEST.arff'\n",
    "path_test_dimension_2 = './datasets/PenDigits/PenDigitsDimension2_TEST.arff'\n",
    "# Train\n",
    "data_1 = arff.load(path_train_dimension_1)\n",
    "data_2 = arff.load(path_train_dimension_2)\n",
    "X = np.array([[*x._values[:-1],*y._values ]for x,y in zip(data_1, data_2)], dtype=float)\n",
    "print(f'Train samples shape {X.shape}')\n",
    "X_train = X[:, :-1]\n",
    "y_train = X[:, -1]\n",
    "\n",
    "# Test \n",
    "data_1 = arff.load(path_test_dimension_1)\n",
    "data_2 = arff.load(path_test_dimension_2)\n",
    "X = np.array([[*x._values[:-1],*y._values ]for x,y in zip(data_1, data_2)], dtype=float)\n",
    "print(f'Test sample shape {X.shape}')\n",
    "X_test = X[:, :-1]\n",
    "y_test = X[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent in SVM 0.0941 s\n",
      "Score 0.9817\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "init_time = timeit.default_timer()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = timeit.default_timer()\n",
    "spent_time = end_time - init_time\n",
    "print(f'Time spent in SVM {spent_time:.4f} s')\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f'Score {score :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.RidgeClassifierCV()\n",
    "X_features = rbf_feature.fit_transform(X_train)\n",
    "clf.fit(X_features, y_train)\n",
    "best_alpha = clf.alpha_\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent in RFF D=50 gamma = 15.8 : 0.0134 s\n",
      "Score RFF D=50 0.0946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for D in [50]:#[10, 17,20, 50, 100, 200, ]:\n",
    "    for g in [15.8]: #np.linspace(0.05, 20, 20):\n",
    "        clf = linear_model.RidgeClassifierCV()\n",
    "        X_features = rbf_feature.fit_transform(X_train)\n",
    "        clf.fit(X_features, y_train)\n",
    "        best_alpha = 0#clf.alpha_\n",
    "        rbf_feature = RBFSampler(gamma=g, n_components=D, random_state=1)\n",
    "        clf = linear_model.RidgeClassifier(alpha=best_alpha)\n",
    "\n",
    "        init_time = timeit.default_timer()\n",
    "        X_features = rbf_feature.fit_transform(X_train)\n",
    "        clf.fit(X_features, y_train)\n",
    "        end_time = timeit.default_timer()\n",
    "        spent_time = end_time - init_time\n",
    "\n",
    "        print(f'Time spent in RFF D={D} gamma = {g} : {spent_time:.4f} s')\n",
    "        X_features_test = rbf_feature.fit_transform(X_test)\n",
    "\n",
    "        score = clf.score(X_features_test, y_test)\n",
    "        print(f'Score RFF D={D} {score :.4f}')\n",
    "\n",
    "        # Usando otro clasificador: \n",
    "        #clf = linear_model.SGDClassifier(max_iter=20, tol=1e-3)\n",
    "        #clf.fit(X_features, y_train)\n",
    "        #s = clf.score(X_features_test, y_test)\n",
    "        #print(f'Score SCD {s}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest covertypes\n",
    "\n",
    "The samples in this dataset correspond to 30×30m patches of forest in the US, collected for the task of predicting each patch’s cover type, i.e. the dominant species of tree. There are seven covertypes, making this a multiclass classification problem. Each sample has 54 features, described on the dataset’s homepage. Some of the features are boolean indicators, while others are discrete or continuous measurements.\n",
    "\n",
    "Source: https://scikit-learn.org/stable/datasets/real_world.html\n",
    "Data Set Characteristics:\n",
    "\n",
    "Classes\n",
    "7\n",
    "Samples total\n",
    "581012\n",
    "Dimensionality\n",
    "54\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  (581012, 54)\n",
      "Target size:  (581012,)\n"
     ]
    }
   ],
   "source": [
    "X,y = fetch_covtype(return_X_y=True)\n",
    "\n",
    "print('Size: ', X.shape)\n",
    "print('Target size: ', y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.6, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo') #multiclass\n",
    "init_time = timeit.default_timer()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = timeit.default_timer()\n",
    "spent_time = end_time - init_time\n",
    "print(f'Time spent in SVM multiclas {spent_time:.4f} s')\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f'Score {score :.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.openml.org/search?type=data&sort=runs&status=any&qualities.NumberOfClasses=lte_1&qualities.NumberOfFeatures=between_100_1000&qualities.NumberOfInstances=between_1000_10000&id=422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blancacanocamarero/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/datasets/_openml.py:414: UserWarning: Multiple active versions of the dataset matching the name topo_2_1 exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "topo = fetch_openml(name='topo_2_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  (8885, 266)\n",
      "Target size:  (8885,)\n",
      "score  0.030565341392334355\n"
     ]
    }
   ],
   "source": [
    "topo.data.shape\n",
    "topo.target.shape\n",
    "\n",
    "test_size_ratio = 0.3\n",
    "print('Size: ', topo.data.shape)\n",
    "print('Target size: ', topo.target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    topo.data, topo.target, test_size= test_size_ratio, random_state=42)\n",
    "\n",
    "g = 0.4\n",
    "D = 100\n",
    "#y_train = np.array(list(y_train))\n",
    "rbf_feature = RBFSampler(gamma=g, n_components=D, random_state=1)\n",
    "\n",
    "clf = linear_model.Ridge(alpha =  1.0)\n",
    "X_features = rbf_feature.fit_transform(X_train)\n",
    "clf.fit(X_features, y_train)\n",
    "\n",
    "X_features_test = rbf_feature.fit_transform(X_test)\n",
    "\n",
    "score = clf.score(X_features_test, y_test)\n",
    "print('score ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.010687335838127643"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), \n",
    "                     RBFSampler(gamma=g, n_components=D, random_state=1), \n",
    "                     linear_model.Ridge(alpha =  1.0))\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6219,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2 = np.array(list(y_train))\n",
    "y_train_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05678472126699319"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('fourier', RBFSampler(n_components=10000, gamma=g)),\n",
    "    ('regression',  linear_model.Ridge(alpha = 2.0))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Random Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Data sets\n",
    "from sklearn.datasets import fetch_covtype\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import fetch_openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  (8885, 266)\n",
      "Target size:  (8885,)\n",
      "After removing constan variance  (8885, 97)\n"
     ]
    }
   ],
   "source": [
    "topo = fetch_openml(name='topo_2_1', version=1)\n",
    "test_size_ratio = 0.3\n",
    "print('Size: ', topo.data.shape)\n",
    "print('Target size: ', topo.target.shape)\n",
    "\n",
    "\n",
    "# Establecer umbral de varianza\n",
    "var_threshold = 0.01\n",
    "X = topo.data.loc[:, topo.data.var() >= var_threshold]\n",
    "print('After removing constan variance ', X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, topo.target, test_size= test_size_ratio, random_state=42)\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03855656604001101"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 100\n",
    "est = KBinsDiscretizer(n_bins=D, encode='ordinal',\n",
    "                                strategy='uniform')\n",
    "\n",
    "# Get best alpha\n",
    "X_features = est.fit_transform(X_train_scaled)\n",
    "clf = linear_model.Ridge(alpha = 0.05)\n",
    "clf.fit(X_features, y_train)\n",
    "X_features_test = est.transform(X_test_scaled)\n",
    "score = clf.score(X_features_test, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
