% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
  aspectratio=32,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolshorizontal
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usetheme[]{Berlin}
\usecolortheme{whale}
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Machine Learning Introduction},
  pdfauthor={Blanca Cano Camarero},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Machine Learning Introduction}
\subtitle{Regularization and bias variance trade-off}
\author{Blanca Cano Camarero}
\date{11 November 2022}
\institute{Universidad Aut√≥noma de Madrid}
\titlegraphic{\includegraphics{../imgs/logos/uam-iic.jpeg}}

\begin{document}
\frame{\titlepage}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt, frame hidden, interior hidden, breakable, sharp corners, enhanced]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
\begin{frame}[allowframebreaks]
  \frametitle{Table of contents}
  \tableofcontents[hideallsubsections]
\end{frame}
\begin{frame}{Last week}
\protect\hypertarget{last-week}{}
\begin{itemize}
\tightlist
\item
  What is machine learning
\item
  Lineal models
\end{itemize}
\end{frame}

\begin{frame}{Motivation of regularization}
\protect\hypertarget{motivation-of-regularization}{}
\begin{itemize}
\tightlist
\item
  Model according to the size of the available training set.
\item
  The number of parameters in not necessarily the most appropriate
  measure of model complexity.
\item
  Face over fitting.
\item
  Retaining a subset of the predictions of discarding the rest exhibits
  high variance.
\end{itemize}
\end{frame}

\begin{frame}{Shrinkage methods}
\protect\hypertarget{shrinkage-methods}{}
\begin{block}{Prediction accuracy}
\protect\hypertarget{prediction-accuracy}{}
\begin{itemize}
\item
  Shrink are more continuous and don't suffer as much from high
  variability.
\item
  When there are many correlated variables in a linea regression model,
  their coefficient can became poorly determined and exhibit high
  variance.
\item
  Wild large positive coefficient on one variable can be canceled y a
  similarly large positive coefficient on its correlated cousin.
\item
  By imposing a size constraint on the coefficient this problem is
  alleviated.
\end{itemize}
\end{block}

\begin{block}{Interpretation}
\protect\hypertarget{interpretation}{}
\begin{itemize}
\tightlist
\item
  We often would like to determine a smaller subset that exhibit the
  strongest effect.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Subset Selection}
\protect\hypertarget{subset-selection}{}
\end{frame}

\begin{frame}{Ridge Regression}
\protect\hypertarget{ridge-regression}{}
\begin{itemize}
\item
  Ridge regression shrinks the regression coefficients by imposing a
  penalty on their size.
\item
  The ridge coefficients minimize a penalized residual sum of
\end{itemize}

\begin{align}
\hat{\beta}^{\text{ridge}}
& = 
\text{argmin}_\beta
    \sum_{i = 1}^N
    \left(
        y_i - \beta_0 
        - \sum_{j = 1}^p
        x_{i j} \beta_j
    \right)^2
\\
\nonumber
&
\text{subject to }
\sum_{j = 1}^p \beta_j^2 \leq t.
\end{align}
\end{frame}

\begin{frame}{Ridge regression properties}
\protect\hypertarget{ridge-regression-properties}{}
\begin{itemize}
\tightlist
\item
  There is a one to one correspondence between the parameter \(\lambda\)
  and \(t\).
\end{itemize}

An equivalent way to write the ridge problem is

\begin{equation}\protect\hypertarget{eq-ridge-argmin}{}{
\hat{\beta}^{\text{ridge}}
= 
\text{argmin}_\beta
\left\{
    \sum_{i = 1}^N
    \left(
        y_i - \beta_0 
        - \sum_{j = 1}^p
        x_{i j} \beta_j
    \right)^2
    + 
    \lambda
    - \sum_{j = 1}^p  \beta_j^2
\right\}
}\label{eq-ridge-argmin}\end{equation}

Where \(\lambda \leq 0\) is a complexity parameter t that controls the
amount of shrinkage.
\end{frame}

\begin{frame}{Matrix form}
\protect\hypertarget{matrix-form}{}
\[
RSS(\lambda) 
= 
(y - X \beta)^T
(Y - X \beta )
+ \lambda \beta^T \beta
\]

The ridge regression solution are easily seen to be

\begin{equation}\protect\hypertarget{eq-ridge-solution}{}{
\hat{\beta}^{\text{ridge}}
 = 
 (X^T X + \lambda I)^{-1}
 X^T y.
}\label{eq-ridge-solution}\end{equation}
\end{frame}

\begin{frame}{Proof ridge}
\protect\hypertarget{proof-ridge}{}
Denote by \(X\) the \(X \times (p+1)\) matrix with each row an input
vector (with a 1 in the first position)
\begin{equation}\protect\hypertarget{eq-ridge-partial-1}{}{
\frac{\partial RSS}{\partial \beta}
= 
-2X^T (y - X \beta) + 2 \lambda \beta
}\label{eq-ridge-partial-1}\end{equation}

\begin{equation}\protect\hypertarget{eq-ridge-partial-2}{}{
\frac{\partial \partial RSS}{\partial \beta \partial \beta^T}
= 
2X^T X + 2 \lambda
}\label{eq-ridge-partial-2}\end{equation}
\end{frame}

\begin{frame}{Proof}
\protect\hypertarget{proof}{}
Assuming that \(X\) has full column rank, hence \(X^T X\) is positive
definite, and \(\lambda > 0\) we set the first derivative to zero

\begin{equation}\protect\hypertarget{eq-ridge-partial-3}{}{
X^T (y - X \beta ) = \lambda \beta
}\label{eq-ridge-partial-3}\end{equation}

to obtain the unique solution
\begin{equation}\protect\hypertarget{eq-ridge-partial-4}{}{
\hat \beta
= 
(X^T X - I \lambda)^{-1} X^T y.
}\label{eq-ridge-partial-4}\end{equation}
\end{frame}

\begin{frame}{Which component are more affected by shrinkage}
\protect\hypertarget{which-component-are-more-affected-by-shrinkage}{}
\emph{Singular value decomposition}

\begin{equation}\protect\hypertarget{eq-SVD}{}{
X = U D V^T
}\label{eq-SVD}\end{equation}

Here \(U\) and \(V\) are \(N \times p\) and \(p \times p\) orthogonal
matrices.

\(D\) is a diagonal matrix of singular values : \[
d_1 \geq d_2 \geq \ldots \geq d_p \geq 0
\].

Now the ridge regression is

\begin{align}
X \hat{\beta}^{\text{ridge}}
& =
X(X^T X - I \lambda)^{-1} X^T y
\\
& =  
U D (D^2 + \lambda I)^{-1} D U^T y
\\
& =
\sum_{j = 1}^p 
u_{* i} \frac{d_{j j} ^2}{d_{j j}^2 + \lambda } u_{* j}^T y. 
\end{align}
\end{frame}

\begin{frame}{Lasso}
\protect\hypertarget{lasso}{}
\begin{align}
\hat{\beta}^{\text{lasso}}
& = 
\text{argmin}_\beta
    \sum_{i = 1}^N
    \left(
        y_i - \beta_0 
        - \sum_{j = 1}^p
        x_{i j} \beta_j
    \right)^2
\\
\nonumber
&
\text{subject to }
\sum_{j = 1}^p |\beta_j| \leq t.
\end{align}
\end{frame}

\begin{frame}{Lasso in the equivalent \emph{Lagragian form}}
\protect\hypertarget{lasso-in-the-equivalent-lagragian-form}{}
\begin{equation}\protect\hypertarget{eq-lasso-argmin}{}{
\hat{\beta}^{\text{lasso}}
= 
\text{argmin}_\beta
\left\{
    \sum_{i = 1}^N
    \left(
        y_i - \beta_0 
        - \sum_{j = 1}^p
        x_{i j} \beta_j
    \right)^2
    + 
    \lambda
    - \sum_{j = 1}^p  |\beta_j|
\right\}
}\label{eq-lasso-argmin}\end{equation}

Computing the lasso solution is a quadratic programming (see
{``Quadratic Programming''} (2022)) Least Angle Regression
\end{frame}

\begin{frame}{PCR}
\protect\hypertarget{pcr}{}
principal component regression (PCR)
\end{frame}

\begin{frame}{Elastic net penalty}
\protect\hypertarget{elastic-net-penalty}{}
\[
\lambda \sum_j \alpha \beta_j^2 + (1 - \alpha) |\beta_j|
\]
\end{frame}

\begin{frame}{Other generalizations ?}
\protect\hypertarget{other-generalizations}{}
\end{frame}

\begin{frame}{More generalized}
\protect\hypertarget{more-generalized}{}
\begin{equation}\protect\hypertarget{eq-generalization-argmin}{}{
\hat{\beta}^{\text{general}}
= 
\text{argmin}_\beta
\left\{
    \sum_{i = 1}^N
    \left(
        y_i - \beta_0 
        - \sum_{j = 1}^p
        x_{i j} \beta_j
    \right)^2
    + 
    \lambda
    - \sum_{j = 1}^p  \alpha_j |\beta_j|^p
\right\}
}\label{eq-generalization-argmin}\end{equation} subject to
\(\alpha_j \geq 0\) and \[
\sum_{j = 1}^p  \alpha_j = 1. 
\]

\textbf{Cons: It is worthy since this method is an heuristic?}
\end{frame}

\begin{frame}{Incorporating prior knowledge}
\protect\hypertarget{incorporating-prior-knowledge}{}
\$\$
\end{frame}

\begin{frame}{\hat{\beta}\^{}\{\text{prior}\}}
\protect\hypertarget{section}{}
\text{argmin}\emph{\beta \left\{ \sum}\{i = 1\}\^{}N \left( y\_i -
\beta\emph{0 - \sum}\{j = 1\}\^{}p x\_\{i j\} \beta\emph{j \right)\^{}2
+ - \sum}\{j = 1\}\^{}p \lambda\_j \textbar{}\beta\_j\textbar\^{}q
\right\} \$\$ \{\#eq-prio\}

\textbf{Cons} Opinion of Rich Sutton (see his webpage {``The Bitter
Lesson''} (2022)): \emph{And the human-knowledge approach tends to
complicate methods in ways that make them less suited to taking
advantage of general methods leveraging computation.}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-QuadraticPrograming}{}}%
{``Quadratic Programming.''} 2022. 2022.
\url{https://en.wikipedia.org/wiki/Quadratic_programming}.

\leavevmode\vadjust pre{\hypertarget{ref-TheBitterLesson}{}}%
{``The Bitter Lesson.''} 2022. 2022.
\url{http://www.incompleteideas.net/IncIdeas/BitterLesson.html}.

\end{CSLReferences}
\end{frame}



\end{document}
