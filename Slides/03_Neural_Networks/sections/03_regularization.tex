\section{Regularization}

\begin{frame}
    \frametitle{Overview}
    Often \textbf{neural networks have to many weights} and will overfit the data at 
    the global minimum.
    
    \begin{itemize}
        \item Early stopping.
        \item Weight decay. 
        \item Weight elimination.
    \end{itemize}
    \cite{AUniversalLawofRobustness} 
    ( over-parameterized regime where the parameters of
     the model exceed the size of the training dataset.)
\end{frame}

